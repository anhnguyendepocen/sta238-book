<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Extended Example: Reasoning About Goodness of Fit | STA238: Probability, Statistics, and Data Analysis</title>
  <meta name="description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  <meta name="generator" content="bookdown 0.21.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Extended Example: Reasoning About Goodness of Fit | STA238: Probability, Statistics, and Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Extended Example: Reasoning About Goodness of Fit | STA238: Probability, Statistics, and Data Analysis" />
  
  <meta name="twitter:description" content="This book represents part of the course materials for STA238 at the University of Toronto" />
  

<meta name="author" content="Alison Gibbs and Alex Stringer" />


<meta name="date" content="2020-10-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="section-supplement-to-chapter-23-and-24.html"/>
<link rel="next" href="section-supplement-to-evans-rosenthal-section-7-2.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STA238 University of Toronto</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><i class="fa fa-check"></i><b>2</b> Introduction to Data Analysis: Data Input and Basic Summaries</a><ul>
<li class="chapter" data-level="2.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-old-faithful"><i class="fa fa-check"></i><b>2.1</b> Old Faithful</a><ul>
<li class="chapter" data-level="2.1.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-read-in-the-data"><i class="fa fa-check"></i><b>2.1.1</b> Read in the data</a></li>
<li class="chapter" data-level="2.1.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-graphical-summaries"><i class="fa fa-check"></i><b>2.1.2</b> Graphical Summaries</a></li>
<li class="chapter" data-level="2.1.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-numerical-summaries"><i class="fa fa-check"></i><b>2.1.3</b> Numerical Summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-drilling"><i class="fa fa-check"></i><b>2.2</b> Drilling</a><ul>
<li class="chapter" data-level="2.2.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-read-in-data"><i class="fa fa-check"></i><b>2.2.1</b> Read in data</a></li>
<li class="chapter" data-level="2.2.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-graphical-summaries-1"><i class="fa fa-check"></i><b>2.2.2</b> Graphical summaries</a></li>
<li class="chapter" data-level="2.2.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-numerical-summaries-1"><i class="fa fa-check"></i><b>2.2.3</b> Numerical summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
<li class="chapter" data-level="2.4" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-extended-example-smoking-and-age-and-mortality"><i class="fa fa-check"></i><b>2.4</b> Extended example: smoking and age and mortality</a><ul>
<li class="chapter" data-level="2.4.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-1"><i class="fa fa-check"></i><b>2.4.1</b> Exercises</a></li>
<li class="chapter" data-level="2.4.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-association-between-smoking-and-mortality"><i class="fa fa-check"></i><b>2.4.2</b> Association between smoking and mortality</a></li>
<li class="chapter" data-level="2.4.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-2"><i class="fa fa-check"></i><b>2.4.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-case-study-rental-housing-in-toronto"><i class="fa fa-check"></i><b>2.5</b> Case study: rental housing in Toronto</a><ul>
<li class="chapter" data-level="2.5.1" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-load-the-data"><i class="fa fa-check"></i><b>2.5.1</b> Load the data</a></li>
<li class="chapter" data-level="2.5.2" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-i-what-does-the-data-look-like"><i class="fa fa-check"></i><b>2.5.2</b> Analysis I: what does the data look like?</a></li>
<li class="chapter" data-level="2.5.3" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-ii-do-different-wards-have-different-quality-housing"><i class="fa fa-check"></i><b>2.5.3</b> Analysis II: Do different wards have different quality housing?</a></li>
<li class="chapter" data-level="2.5.4" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-analysis-iii-trends-in-quality-over-time"><i class="fa fa-check"></i><b>2.5.4</b> Analysis III: trends in quality over time</a></li>
<li class="chapter" data-level="2.5.5" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-summary"><i class="fa fa-check"></i><b>2.5.5</b> Summary</a></li>
<li class="chapter" data-level="2.5.6" data-path="section-introduction-to-data-analysis-data-input-and-basic-summaries.html"><a href="section-introduction-to-data-analysis-data-input-and-basic-summaries.html#section-exercises-3"><i class="fa fa-check"></i><b>2.5.6</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><i class="fa fa-check"></i><b>3</b> Introduction to Statistics: Law of Large Numbers and Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-law-of-large-numbers-chapter-13"><i class="fa fa-check"></i><b>3.1</b> Law of Large Numbers (Chapter 13)</a><ul>
<li class="chapter" data-level="3.1.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-extended-example-the-probability-of-heads"><i class="fa fa-check"></i><b>3.1.1</b> Extended example: the probability of heads</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-central-limit-theorem-chapter-14"><i class="fa fa-check"></i><b>3.2</b> Central Limit Theorem (Chapter 14)</a><ul>
<li class="chapter" data-level="3.2.1" data-path="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html"><a href="section-introduction-to-statistics-law-of-large-numbers-and-central-limit-theorem.html#section-extended-example-the-probability-of-heads-1"><i class="fa fa-check"></i><b>3.2.1</b> Extended example: the probability of heads</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="section-statistical-models.html"><a href="section-statistical-models.html"><i class="fa fa-check"></i><b>4</b> Statistical Models</a><ul>
<li class="chapter" data-level="4.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-statistical-models-chapter-17"><i class="fa fa-check"></i><b>4.1</b> Statistical models (Chapter 17)</a><ul>
<li class="chapter" data-level="4.1.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-linear-regression"><i class="fa fa-check"></i><b>4.1.1</b> Linear Regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-extended-example-ttc-ridership-revenues"><i class="fa fa-check"></i><b>4.1.2</b> Extended example: TTC ridership revenues</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-unbiased-estimators-chapter-19"><i class="fa fa-check"></i><b>4.2</b> Unbiased Estimators (Chapter 19)</a><ul>
<li class="chapter" data-level="4.2.1" data-path="section-statistical-models.html"><a href="section-statistical-models.html#section-simulated-data"><i class="fa fa-check"></i><b>4.2.1</b> Simulated data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><i class="fa fa-check"></i><b>5</b> Evaluating Estimators: Efficiency and Mean Squared Error</a><ul>
<li class="chapter" data-level="5.1" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-estimating-a-uniform-maximum"><i class="fa fa-check"></i><b>5.1</b> Estimating a Uniform Maximum</a></li>
<li class="chapter" data-level="5.2" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-efficiency"><i class="fa fa-check"></i><b>5.2</b> Efficiency</a></li>
<li class="chapter" data-level="5.3" data-path="section-evaluating-estimators-efficiency-and-mean-squared-error.html"><a href="section-evaluating-estimators-efficiency-and-mean-squared-error.html#section-mean-squared-error"><i class="fa fa-check"></i><b>5.3</b> Mean Squared Error</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html"><i class="fa fa-check"></i><b>6</b> Introduction to Bayesian Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-tutorial"><i class="fa fa-check"></i><b>6.1</b> Tutorial</a><ul>
<li class="chapter" data-level="6.1.1" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-frequentistlikelihood-perspective"><i class="fa fa-check"></i><b>6.1.1</b> Frequentist/Likelihood Perspective</a></li>
<li class="chapter" data-level="6.1.2" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-bayesian-inference-introduction"><i class="fa fa-check"></i><b>6.1.2</b> Bayesian Inference: introduction</a></li>
<li class="chapter" data-level="6.1.3" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-flipping-more-coins"><i class="fa fa-check"></i><b>6.1.3</b> Flipping More Coins</a></li>
<li class="chapter" data-level="6.1.4" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-visualization"><i class="fa fa-check"></i><b>6.1.4</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="section-introduction-to-bayesian-inference.html"><a href="section-introduction-to-bayesian-inference.html#section-interactive-app"><i class="fa fa-check"></i><b>6.2</b> Interactive App</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html"><i class="fa fa-check"></i><b>7</b> The Bootstrap</a><ul>
<li class="chapter" data-level="7.1" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-the-bootstrap-chapter-18"><i class="fa fa-check"></i><b>7.1</b> The Bootstrap (Chapter 18)</a><ul>
<li class="chapter" data-level="7.1.1" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-empirical-bootstrap-old-faithful-data"><i class="fa fa-check"></i><b>7.1.1</b> Empirical bootstrap: Old Faithful data</a></li>
<li class="chapter" data-level="7.1.2" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-parametric-bootstrap-software-data"><i class="fa fa-check"></i><b>7.1.2</b> Parametric Bootstrap: software data</a></li>
<li class="chapter" data-level="7.1.3" data-path="section-the-bootstrap.html"><a href="section-the-bootstrap.html#section-extended-example-the-standard-error-of-a-proportion"><i class="fa fa-check"></i><b>7.1.3</b> Extended example: the standard error of a proportion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html"><i class="fa fa-check"></i><b>8</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="8.1" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-maximum-likelihood-chapter-21"><i class="fa fa-check"></i><b>8.1</b> Maximum Likelihood (Chapter 21)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-two-coins"><i class="fa fa-check"></i><b>8.1.1</b> Example: two coins</a></li>
<li class="chapter" data-level="8.1.2" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-unknown-coins-n-2"><i class="fa fa-check"></i><b>8.1.2</b> Example: unknown coins, <span class="math inline">\(n = 2\)</span></a></li>
<li class="chapter" data-level="8.1.3" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-example-unknown-coins-n-bigger-than-2"><i class="fa fa-check"></i><b>8.1.3</b> Example: unknown coins, <span class="math inline">\(n\)</span> bigger than <span class="math inline">\(2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="section-maximum-likelihood.html"><a href="section-maximum-likelihood.html#section-extended-example-rental-housing-in-toronto"><i class="fa fa-check"></i><b>8.2</b> Extended example: rental housing in Toronto</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html"><i class="fa fa-check"></i><b>9</b> Supplement to Chapter 23 and 24</a><ul>
<li class="chapter" data-level="9.1" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-confidence-intervals-for-the-mean-chapter-23"><i class="fa fa-check"></i><b>9.1</b> Confidence Intervals for the Mean (Chapter 23)</a><ul>
<li class="chapter" data-level="9.1.1" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-simulation"><i class="fa fa-check"></i><b>9.1.1</b> Simulation</a></li>
<li class="chapter" data-level="9.1.2" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-gross-calorific-value-measurements-for-osterfeld-262de27"><i class="fa fa-check"></i><b>9.1.2</b> Gross calorific value measurements for Osterfeld 262DE27</a></li>
<li class="chapter" data-level="9.1.3" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-gross-calorific-value-measurements-for-daw-mill-258gb41"><i class="fa fa-check"></i><b>9.1.3</b> Gross calorific value measurements for Daw Mill 258GB41</a></li>
<li class="chapter" data-level="9.1.4" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>9.1.4</b> Bootstrap Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-more-on-confidence-intervals-chapter-24"><i class="fa fa-check"></i><b>9.2</b> More on confidence intervals (Chapter 24)</a><ul>
<li class="chapter" data-level="9.2.1" data-path="section-supplement-to-chapter-23-and-24.html"><a href="section-supplement-to-chapter-23-and-24.html#section-binomial-distribution"><i class="fa fa-check"></i><b>9.2.1</b> Binomial distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html"><i class="fa fa-check"></i><b>10</b> Extended Example: Reasoning About Goodness of Fit</a><ul>
<li class="chapter" data-level="10.1" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-go-and-read-the-blog-post"><i class="fa fa-check"></i><b>10.1</b> Go and read the blog post</a></li>
<li class="chapter" data-level="10.2" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-distribution-of-last-digits"><i class="fa fa-check"></i><b>10.2</b> Distribution of last digits</a><ul>
<li class="chapter" data-level="10.2.1" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-read-in-the-data-1"><i class="fa fa-check"></i><b>10.2.1</b> Read in the data</a></li>
<li class="chapter" data-level="10.2.2" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-make-the-histogram"><i class="fa fa-check"></i><b>10.2.2</b> Make the histogram</a></li>
<li class="chapter" data-level="10.2.3" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-testing-goodness-of-fit-simulation"><i class="fa fa-check"></i><b>10.2.3</b> Testing goodness of fit: simulation</a></li>
<li class="chapter" data-level="10.2.4" data-path="section-extended-example-reasoning-about-goodness-of-fit.html"><a href="section-extended-example-reasoning-about-goodness-of-fit.html#section-testing-goodness-of-fit-math"><i class="fa fa-check"></i><b>10.2.4</b> Testing goodness of fit: math</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html"><i class="fa fa-check"></i><b>11</b> Supplement to Evans &amp; Rosenthal Section 7.2</a><ul>
<li class="chapter" data-level="11.1" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-estimation-in-bayesian-inference-general-ideas"><i class="fa fa-check"></i><b>11.1</b> Estimation in Bayesian Inference: general ideas</a><ul>
<li class="chapter" data-level="11.1.1" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-the-prior"><i class="fa fa-check"></i><b>11.1.1</b> The Prior</a></li>
<li class="chapter" data-level="11.1.2" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-the-posterior"><i class="fa fa-check"></i><b>11.1.2</b> The Posterior</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-estimation-in-bayesian-inference-point-and-interval-estimation"><i class="fa fa-check"></i><b>11.2</b> Estimation in Bayesian Inference: point and interval estimation</a></li>
<li class="chapter" data-level="11.3" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-choosing-a-prior"><i class="fa fa-check"></i><b>11.3</b> Choosing a Prior</a><ul>
<li class="chapter" data-level="11.3.1" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-conjugate-priors"><i class="fa fa-check"></i><b>11.3.1</b> Conjugate Priors</a></li>
<li class="chapter" data-level="11.3.2" data-path="section-supplement-to-evans-rosenthal-section-7-2.html"><a href="section-supplement-to-evans-rosenthal-section-7-2.html#section-setting-hyperparameters-by-moment-matching"><i class="fa fa-check"></i><b>11.3.2</b> Setting Hyperparameters by moment-matching</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html"><i class="fa fa-check"></i><b>12</b> Predictive Modelling</a><ul>
<li class="chapter" data-level="12.1" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-overview"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-plug-in-prediction-coin-flipping"><i class="fa fa-check"></i><b>12.2</b> Plug-in prediction: coin flipping</a></li>
<li class="chapter" data-level="12.3" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-bayesian-prediction-coin-flipping"><i class="fa fa-check"></i><b>12.3</b> Bayesian Prediction: coin flipping</a></li>
<li class="chapter" data-level="12.4" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-extended-example-income-and-advertsing-datasets"><i class="fa fa-check"></i><b>12.4</b> Extended example: Income and Advertsing datasets</a></li>
<li class="chapter" data-level="12.5" data-path="section-predictive-modelling.html"><a href="section-predictive-modelling.html#section-extended-example-predicting-call-centre-wait-times"><i class="fa fa-check"></i><b>12.5</b> Extended example: predicting call centre wait times</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html"><i class="fa fa-check"></i><b>13</b> Installing R and RStudio</a><ul>
<li class="chapter" data-level="13.1" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-installing-r"><i class="fa fa-check"></i><b>13.1</b> Installing R</a></li>
<li class="chapter" data-level="13.2" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-installing-rstudio"><i class="fa fa-check"></i><b>13.2</b> Installing RStudio</a></li>
<li class="chapter" data-level="13.3" data-path="section-installing-r-and-rstudio.html"><a href="section-installing-r-and-rstudio.html#section-using-rmarkdown"><i class="fa fa-check"></i><b>13.3</b> Using RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html"><i class="fa fa-check"></i><b>14</b> Assigned Exercises from MIPS</a><ul>
<li class="chapter" data-level="14.1" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-15-and-16"><i class="fa fa-check"></i><b>14.1</b> Chapters 15 and 16</a></li>
<li class="chapter" data-level="14.2" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-13-and-14"><i class="fa fa-check"></i><b>14.2</b> Chapters 13 and 14</a></li>
<li class="chapter" data-level="14.3" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapters-17-and-19"><i class="fa fa-check"></i><b>14.3</b> Chapters 17 and 19</a></li>
<li class="chapter" data-level="14.4" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-20"><i class="fa fa-check"></i><b>14.4</b> Chapter 20</a></li>
<li class="chapter" data-level="14.5" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-evans-and-rosenthal-chapter-7"><i class="fa fa-check"></i><b>14.5</b> Evans and Rosenthal, Chapter 7</a></li>
<li class="chapter" data-level="14.6" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-18"><i class="fa fa-check"></i><b>14.6</b> Chapter 18</a></li>
<li class="chapter" data-level="14.7" data-path="section-assigned-exercises-from-mips.html"><a href="section-assigned-exercises-from-mips.html#section-chapter-21"><i class="fa fa-check"></i><b>14.7</b> Chapter 21</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STA238: Probability, Statistics, and Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-extended-example-reasoning-about-goodness-of-fit" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Extended Example: Reasoning About Goodness of Fit</h1>
<p>This chapter is a bit different: we introduce the idea of “goodness of fit” through
implementing the analysis in a blog post discussing a disputed paper in a
Psychology journal. You can find the article here: <a href="http://datacolada.org/74">http://datacolada.org/74</a></p>
<div class="sourceCode" id="section-cb299"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb299-1" title="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<div id="section-go-and-read-the-blog-post" class="section level2">
<h2><span class="header-section-number">10.1</span> Go and read the blog post</h2>
<p>To start, go read this blog post: <a href="http://datacolada.org/74">http://datacolada.org/74</a>.
This should take you at least an hour or so to do in detail, if not longer. It
is a major part of this week’s materials, effectively replacing textbook readings.
It is not optional, and will be tested on assignments and tests.</p>
<p><strong>Exercise</strong>: summarize this study in your own words. Two or three sentences
should suffice. What did they do, how did they do it, and what were they trying
to find out? It is important that you understand this before you move on.</p>
</div>
<div id="section-distribution-of-last-digits" class="section level2">
<h2><span class="header-section-number">10.2</span> Distribution of last digits</h2>
<p>The distribution of digits in numeric data is of considerable interest in certain
fields. In forensic accounting, where investigators try to identify fraudulent
accounting practice by identifying systematic anomalies in financial records,
the relative frequency with which different digits occur can indicate potential
fraud if it differs from what you would expect. It is well-established that the
last digit, in particular, of numeric data should be distributed pretty evenly
between the numbers <span class="math inline">\(0 - 9\)</span> in any given set of data.</p>
<p>So, let’s look at the last digit of the measurements from the hand sanitizer study.
The data is available from <a href="http://datacolada.org/appendix/74/">http://datacolada.org/appendix/74/</a> and their <code>R</code> code can be found at <a href="http://datacolada.org/appendix/74/74%20-%20DataColada%20-%20Decoy%20Sanitizer%20-%202018%2008%2023.R">http://datacolada.org/appendix/74/74%20-%20DataColada%20-%20Decoy%20Sanitizer%20-%202018%2008%2023.R</a>. Here we
use our own <code>R</code> code but I borrow parts from theirs.</p>
<div id="section-read-in-the-data-1" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Read in the data</h3>
<p>First, read in the data as usual:</p>
<div class="sourceCode" id="section-cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" title="1">study1 &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_csv</span>(</a>
<a class="sourceLine" id="cb300-2" title="2">  <span class="dt">file =</span> <span class="st">&quot;http://datacolada.org/appendix/74/Study%201%20-%20Decoy%20Effect.csv&quot;</span>,</a>
<a class="sourceLine" id="cb300-3" title="3">  <span class="dt">col_names =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb300-4" title="4">  <span class="dt">col_types =</span> stringr<span class="op">::</span><span class="kw">str_c</span>(<span class="kw">rep</span>(<span class="st">&quot;n&quot;</span>,<span class="dv">42</span>),<span class="dt">collapse =</span> <span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb300-5" title="5">)</a>
<a class="sourceLine" id="cb300-6" title="6"><span class="kw">glimpse</span>(study1)</a></code></pre></div>
<pre><code>Observations: 40
Variables: 42
$ Subject                                                   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,…
$ `Group (1=experimental condition, 0 = control condition)` &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, …
$ Day1                                                      &lt;dbl&gt; 55, 60, 63, 55, 60, 60, 35, 55, 45, 75, 50, 70, 60, 40, 35, 50, 50…
$ Day2                                                      &lt;dbl&gt; 45, 55, 40, 50, 40, 20, 40, 40, 50, 55, 45, 55, 45, 45, 50, 55, 45…
$ Day3                                                      &lt;dbl&gt; 45, 55, 50, 40, 15, 90, 85, 20, 90, 35, 55, 50, 30, 35, 60, 65, 45…
$ Day4                                                      &lt;dbl&gt; 40, 55, 60, 40, 40, 60, 45, 35, 90, 45, 55, 55, 35, 35, 60, 60, 35…
$ Day5                                                      &lt;dbl&gt; 45, 50, 25, 45, 75, 65, 55, 30, 55, 60, 53, 50, 50, 40, 65, 63, 47…
$ Day6                                                      &lt;dbl&gt; 45, 45, 35, 60, 65, 60, 45, 50, 45, 40, 55, 50, 43, 50, 55, 65, 50…
$ Day7                                                      &lt;dbl&gt; 55, 45, 55, 85, 60, 40, 40, 45, 45, 45, 50, 40, 40, 45, 55, 60, 37…
$ Day8                                                      &lt;dbl&gt; 60, 40, 40, 55, 55, 37, 37, 60, 90, 50, 55, 45, 40, 30, 63, 60, 35…
$ Day9                                                      &lt;dbl&gt; 45, 40, 33, 65, 60, 33, 40, 40, 100, 40, 45, 43, 37, 30, 60, 63, 3…
$ Day10                                                     &lt;dbl&gt; 67, 40, 50, 80, 50, 60, 45, 50, 93, 36, 40, 40, 50, 45, 60, 65, 50…
$ Day11                                                     &lt;dbl&gt; 65, 56, 40, 65, 60, 80, 65, 75, 87, 50, 50, 43, 53, 50, 65, 65, 47…
$ Day12                                                     &lt;dbl&gt; 70, 40, 50, 65, 60, 60, 45, 55, 80, 60, 55, 43, 45, 55, 65, 60, 55…
$ Day13                                                     &lt;dbl&gt; 80, 40, 25, 70, 60, 60, 55, 75, 89, 65, 45, 40, 37, 65, 65, 70, 40…
$ Day14                                                     &lt;dbl&gt; 75, 45, 45, 50, 70, 70, 55, 70, 80, 70, 50, 40, 55, 55, 60, 60, 45…
$ Day15                                                     &lt;dbl&gt; 70, 50, 50, 65, 60, 65, 55, 75, 75, 75, 50, 45, 55, 55, 65, 55, 45…
$ Day16                                                     &lt;dbl&gt; 80, 55, 50, 65, 60, 55, 50, 95, 80, 70, 55, 45, 55, 50, 65, 75, 40…
$ Day17                                                     &lt;dbl&gt; 70, 55, 45, 65, 55, 60, 50, 85, 85, 70, 55, 40, 65, 60, 60, 70, 43…
$ Day18                                                     &lt;dbl&gt; 75, 50, 45, 55, 55, 55, 45, 80, 80, 60, 50, 40, 60, 50, 55, 70, 40…
$ Day19                                                     &lt;dbl&gt; 70, 45, 45, 60, 65, 75, 40, 85, 80, 65, 45, 40, 65, 45, 55, 60, 47…
$ Day20                                                     &lt;dbl&gt; 65, 50, 40, 60, 70, 70, 55, 85, 75, 55, 45, 43, 55, 65, 65, 55, 55…
$ `Day21 (Beginning of intervention)`                       &lt;dbl&gt; 85, 55, 65, 80, 70, 90, 65, 85, 85, 75, 55, 40, 60, 70, 65, 65, 60…
$ Day22                                                     &lt;dbl&gt; 85, 75, 65, 75, 75, 45, 50, 95, 60, 55, 50, 45, 65, 55, 55, 60, 55…
$ Day23                                                     &lt;dbl&gt; 90, 45, 70, 90, 65, 75, 70, 90, 80, 70, 85, 55, 70, 45, 80, 70, 45…
$ Day24                                                     &lt;dbl&gt; 85, 60, 55, 120, 80, 80, 75, 90, 85, 70, 70, 55, 70, 65, 75, 70, 6…
$ Day25                                                     &lt;dbl&gt; 75, 50, 60, 105, 70, 100, 75, 95, 70, 75, 70, 75, 75, 60, 70, 85, …
$ Day26                                                     &lt;dbl&gt; 75, 50, 70, 100, 70, 95, 65, 85, 60, 45, 75, 80, 55, 75, 70, 90, 6…
$ Day27                                                     &lt;dbl&gt; 65, 35, 55, 95, 55, 75, 60, 70, 70, 70, 80, 60, 75, 45, 75, 75, 35…
$ Day28                                                     &lt;dbl&gt; 75, 55, 40, 90, 60, 80, 75, 60, 70, 75, 55, 55, 65, 45, 80, 70, 45…
$ Day29                                                     &lt;dbl&gt; 75, 60, 65, 90, 80, 75, 65, 75, 85, 70, 60, 65, 80, 70, 55, 85, 60…
$ Day30                                                     &lt;dbl&gt; 80, 55, 65, 80, 85, 80, 60, 70, 75, 60, 65, 70, 75, 85, 75, 70, 65…
$ Day31                                                     &lt;dbl&gt; 75, 65, 70, 85, 75, 60, 55, 65, 75, 65, 60, 55, 80, 65, 60, 85, 55…
$ Day32                                                     &lt;dbl&gt; 50, 45, 75, 125, 75, 65, 40, 85, 75, 55, 60, 65, 65, 50, 75, 75, 5…
$ Day33                                                     &lt;dbl&gt; 70, 40, 55, 120, 95, 70, 55, 80, 80, 50, 65, 70, 75, 55, 70, 65, 4…
$ Day34                                                     &lt;dbl&gt; 75, 55, 50, 110, 70, 60, 60, 80, 85, 55, 55, 75, 75, 60, 55, 70, 7…
$ Day35                                                     &lt;dbl&gt; 65, 55, 65, 90, 85, 85, 55, 95, 80, 45, 75, 55, 70, 40, 70, 70, 70…
$ Day36                                                     &lt;dbl&gt; 75, 60, 45, 95, 90, 75, 60, 90, 85, 70, 65, 80, 90, 65, 65, 75, 45…
$ Day37                                                     &lt;dbl&gt; 70, 50, 50, 105, 45, 65, 75, 75, 70, 35, 65, 85, 65, 70, 80, 90, 5…
$ Day38                                                     &lt;dbl&gt; 75, 45, 55, 110, 75, 75, 70, 70, 80, 65, 70, 80, 60, 60, 65, 85, 5…
$ Day39                                                     &lt;dbl&gt; 90, 65, 65, 115, 80, 80, 55, 65, 90, 60, 80, 70, 75, 55, 90, 80, 7…
$ Day40                                                     &lt;dbl&gt; 85, 70, 65, 105, 75, 85, 75, 70, 95, 65, 65, 75, 70, 60, 85, 80, 6…</code></pre>
<p><strong>Exercise</strong>: download the data by pasting the link into a web browser.
Print out the header on the command line or open the <code>.csv</code> file in Excel or
otherwise. Verify that the <code>col_names</code> and <code>col_types</code> arguments I provided
are correct.</p>
<p>The data is in “wide” format– each day has its own column. We want one column
for subject ID, one for Day, and one for measurement. Let’s reformat the data:</p>
<div class="sourceCode" id="section-cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" title="1">study1_long &lt;-<span class="st"> </span>study1 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb302-2" title="2"><span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(day,measurement,Day1<span class="op">:</span>Day40)</a>
<a class="sourceLine" id="cb302-3" title="3"><span class="kw">glimpse</span>(study1_long)</a></code></pre></div>
<pre><code>Observations: 1,600
Variables: 4
$ Subject                                                   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,…
$ `Group (1=experimental condition, 0 = control condition)` &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, …
$ day                                                       &lt;chr&gt; &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;D…
$ measurement                                               &lt;dbl&gt; 55, 60, 63, 55, 60, 60, 35, 55, 45, 75, 50, 70, 60, 40, 35, 50, 50…</code></pre>
<p>We previously had <span class="math inline">\(40\)</span> subjects each with <span class="math inline">\(40\)</span> columns of measurements; now we
have <span class="math inline">\(1,600\)</span> rows, which looks good to me. Let’s further clean up the data: we
need to</p>
<ol style="list-style-type: decimal">
<li>Rename the colums so they are pleasant (yes, this is important!),</li>
<li>Extract the last digit of each measurement and save it in a new column.</li>
</ol>
<p>Let’s do this. We’ll use the <code>substr</code> function to choose the last digit of each
number. Type <code>?substr</code> to learn about this function.</p>
<div class="sourceCode" id="section-cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" title="1">study1_clean &lt;-<span class="st"> </span>study1_long <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb304-2" title="2"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">subject =</span> Subject,</a>
<a class="sourceLine" id="cb304-3" title="3">         <span class="dt">group =</span> <span class="st">`</span><span class="dt">Group (1=experimental condition, 0 = control condition)</span><span class="st">`</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb304-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">last_digit =</span> <span class="kw">as.numeric</span>(<span class="kw">substr</span>(measurement,<span class="kw">nchar</span>(measurement),<span class="kw">nchar</span>(measurement))))</a>
<a class="sourceLine" id="cb304-5" title="5"></a>
<a class="sourceLine" id="cb304-6" title="6"><span class="kw">glimpse</span>(study1_clean)</a></code></pre></div>
<pre><code>Observations: 1,600
Variables: 5
$ subject     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 3…
$ group       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ day         &lt;chr&gt; &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, &quot;Day1&quot;, …
$ measurement &lt;dbl&gt; 55, 60, 63, 55, 60, 60, 35, 55, 45, 75, 50, 70, 60, 40, 35, 50, 50, 60, 55, 50, 50, 25, 45, 60, 70, 10, 60, 80, …
$ last_digit  &lt;dbl&gt; 5, 0, 3, 5, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0, 5, 0, 5, 5, 5, 5, 5, 5, 0, 0…</code></pre>
<p>Looks clean to me!</p>
</div>
<div id="section-make-the-histogram" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Make the histogram</h3>
<p>Okay, now consider Figure 1 in the blog post. They filter out observations
ending in <span class="math inline">\(0\)</span> or <span class="math inline">\(5\)</span>, because the authors of the disputed paper claim to have
occasionally used a scale with <span class="math inline">\(5\)</span>-gram precision, and occasionally one with
<span class="math inline">\(1\)</span>-gram precision (this alone is suspect…). They then make a histogram
of all the last digits. We can do this too:</p>
<div class="sourceCode" id="section-cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" title="1">study1_clean <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-2" title="2"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>(last_digit <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb306-3" title="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> last_digit)) <span class="op">+</span></a>
<a class="sourceLine" id="cb306-4" title="4"><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb306-5" title="5"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;count&quot;</span>,<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>,<span class="dt">fill =</span> <span class="st">&quot;lightblue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb306-6" title="6"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>),<span class="dt">labels =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb306-7" title="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Study 1: Last digit strikingly not uniform&quot;</span>,</a>
<a class="sourceLine" id="cb306-8" title="8">       <span class="dt">x =</span> <span class="st">&quot;Last Digit (0&#39;s and 5&#39;s removed)&quot;</span>,</a>
<a class="sourceLine" id="cb306-9" title="9">       <span class="dt">y =</span> <span class="st">&quot;Frequency&quot;</span>)</a></code></pre></div>
<p><img src="book_files/figure-html/digits-hist-1-1.png" width="672" /></p>
<p>I called this plot a “histogram” (which it is), but I used <code>geom_bar(stat = &quot;count&quot;)</code> to create
it. I did this because I wanted the bins to be at specific values. It’s still a histogram (why?).</p>
</div>
<div id="section-testing-goodness-of-fit-simulation" class="section level3">
<h3><span class="header-section-number">10.2.3</span> Testing goodness of fit: simulation</h3>
<p>If you expect the last digits of a set of numbers to be evenly-distributed across
the values <span class="math inline">\(0 - 9\)</span>, then this plot might look surprising. But can we conclude
that something is wrong, just by looking at a plot? What if the real underlying
distribution of digits is actually evenly-distributed, and we just got a weird
sample– we’d be making an incorrect harsh judgement.</p>
<p>We’re going to ask the question: <strong>if the underlying distribution of last digits
really was evenly distributed, what is the probability of seeing the data that
we saw, or a dataset that is even more extreme under this hypothesis?</strong>.</p>
<p>That’s a mouthful! But it’s a good question to ask. If it’s really, really unlikely
that we see what we saw (or something even further) if the claim of even distribution
is true, then this provides <strong>evidence</strong> against the notion that the digits are
actually evenly distributed. And this provides evidence that there is something
funny in the data.</p>
<p>We are going to do a simulation to investigate this claim. We are going to</p>
<ol style="list-style-type: decimal">
<li>Generate a bunch of datasets the same size as ours but where the distribution of the last digit
actually is evenly distributed across <span class="math inline">\(0 - 9\)</span>, and</li>
<li>Record the proportion of digits in each that are <span class="math inline">\(3\)</span> or <span class="math inline">\(7\)</span>, and</li>
<li>Compute the proportion of our simulated datasets that have a proportion
of 3’s or 7’s as high, or higher, as what we saw in our sample.</li>
</ol>
<p>There are a few details that we can’t get exactly right here: the real data was
generated by sampling a bunch of values that ended in <span class="math inline">\(0&#39;s\)</span> or <span class="math inline">\(5&#39;s\)</span> and then filtering
these out, which is behaviour that I don’t know how to replicate exactly. We also
could consider the distribution of <span class="math inline">\(3&#39;s\)</span> and <span class="math inline">\(7&#39;s\)</span> separately, or jointly (using
“and” instead of “or”). I order to keep this idea simple and big-picture, we’re
going to ignore these details here.</p>
<p>The first question is, how do we generate data that has last digits evenly distributed?
Well, <em>any</em> random numbers should work, but to keep things consistent with the real
data, let’s try generating from a normal distribution with mean and variance equal
to the sample mean and variance of our data, rounded to the nearest integer:</p>
<div class="sourceCode" id="section-cb307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb307-1" title="1">mn &lt;-<span class="st"> </span><span class="kw">mean</span>(study1_clean<span class="op">$</span>measurement)</a>
<a class="sourceLine" id="cb307-2" title="2">ss &lt;-<span class="st"> </span><span class="kw">sd</span>(study1_clean<span class="op">$</span>measurement)</a>
<a class="sourceLine" id="cb307-3" title="3">testnumbers &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">rnorm</span>(<span class="dv">10000</span>,mn,ss))</a>
<a class="sourceLine" id="cb307-4" title="4"><span class="co"># Plot a chart of the last digits</span></a>
<a class="sourceLine" id="cb307-5" title="5"><span class="kw">tibble</span>(<span class="dt">x =</span> testnumbers) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb307-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">last_digit =</span> <span class="kw">as.numeric</span>(<span class="kw">substr</span>(x,<span class="kw">nchar</span>(x),<span class="kw">nchar</span>(x)))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb307-7" title="7"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> last_digit)) <span class="op">+</span></a>
<a class="sourceLine" id="cb307-8" title="8"><span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb307-9" title="9"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;count&quot;</span>,<span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>,<span class="dt">fill =</span> <span class="st">&quot;lightblue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb307-10" title="10"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>),<span class="dt">labels =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb307-11" title="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Last digits of normal random sample&quot;</span>,</a>
<a class="sourceLine" id="cb307-12" title="12">       <span class="dt">x =</span> <span class="st">&quot;Last Digit&quot;</span>,</a>
<a class="sourceLine" id="cb307-13" title="13">       <span class="dt">y =</span> <span class="st">&quot;Frequency&quot;</span>)</a></code></pre></div>
<p><img src="book_files/figure-html/even-dist-1-1.png" width="672" /></p>
<p>Looks pretty uniform to me! Let’s proceed with our simulation:</p>
<div class="sourceCode" id="section-cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" title="1"><span class="kw">set.seed</span>(<span class="dv">789685</span>)</a>
<a class="sourceLine" id="cb308-2" title="2"><span class="co"># Create a function that simulates a dataset</span></a>
<a class="sourceLine" id="cb308-3" title="3"><span class="co"># and returns the proportion of last digits</span></a>
<a class="sourceLine" id="cb308-4" title="4"><span class="co"># that are either 3 or 7</span></a>
<a class="sourceLine" id="cb308-5" title="5">N &lt;-<span class="st"> </span><span class="kw">nrow</span>(study1_clean <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="op">!</span>(last_digit <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">0</span>)))) <span class="co"># Size of dataset to simulate</span></a>
<a class="sourceLine" id="cb308-6" title="6">B &lt;-<span class="st"> </span><span class="fl">1e04</span> <span class="co"># Number of simulations to do- 1 million (!)</span></a>
<a class="sourceLine" id="cb308-7" title="7">mn &lt;-<span class="st"> </span><span class="kw">mean</span>(study1_clean<span class="op">$</span>measurement)</a>
<a class="sourceLine" id="cb308-8" title="8">ss &lt;-<span class="st"> </span><span class="kw">sd</span>(study1_clean<span class="op">$</span>measurement)</a>
<a class="sourceLine" id="cb308-9" title="9">simulate_proportion &lt;-<span class="st"> </span><span class="cf">function</span>() {</a>
<a class="sourceLine" id="cb308-10" title="10">  ds &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">rnorm</span>(N,mn,ss))</a>
<a class="sourceLine" id="cb308-11" title="11">  last_digits &lt;-<span class="st"> </span><span class="kw">substr</span>(ds,<span class="kw">nchar</span>(ds),<span class="kw">nchar</span>(ds))</a>
<a class="sourceLine" id="cb308-12" title="12">  <span class="kw">mean</span>(last_digits <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;3&quot;</span>,<span class="st">&quot;7&quot;</span>))</a>
<a class="sourceLine" id="cb308-13" title="13">}</a>
<a class="sourceLine" id="cb308-14" title="14"><span class="co"># What is the proportion of 3&#39;s and 7&#39;s in our data,</span></a>
<a class="sourceLine" id="cb308-15" title="15"><span class="co"># after filtering out 5&#39;s and 0&#39;s?</span></a>
<a class="sourceLine" id="cb308-16" title="16">study_proportion &lt;-<span class="st"> </span>study1_clean <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb308-17" title="17"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>(last_digit <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">0</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb308-18" title="18"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">p =</span> <span class="kw">mean</span>(last_digit <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">7</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb308-19" title="19"><span class="st">  </span><span class="kw">pull</span>(p) </a>
<a class="sourceLine" id="cb308-20" title="20">study_proportion</a></code></pre></div>
<pre><code>[1] 0.88</code></pre>
<div class="sourceCode" id="section-cb310"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb310-1" title="1"><span class="co"># 88.1%. Wow.</span></a>
<a class="sourceLine" id="cb310-2" title="2"></a>
<a class="sourceLine" id="cb310-3" title="3"><span class="co"># Perform the simulation:</span></a>
<a class="sourceLine" id="cb310-4" title="4">sim_results &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>B <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-5" title="5"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">simulate_proportion</span>()) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-6" title="6"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">as.numeric</span>(.x <span class="op">&gt;=</span><span class="st"> </span>study_proportion)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-7" title="7"><span class="st">  </span><span class="kw">reduce</span>(c)</a>
<a class="sourceLine" id="cb310-8" title="8"></a>
<a class="sourceLine" id="cb310-9" title="9"><span class="co"># This is a vector of 0/1 which says whether each simulation&#39;s proportion of</span></a>
<a class="sourceLine" id="cb310-10" title="10"><span class="co"># 3&#39;s and 7&#39;s exceeded the study proportion. Its mean is the simulated probability</span></a>
<a class="sourceLine" id="cb310-11" title="11"><span class="co"># of seeing what we saw in the study, if the digits are actually evenly distributed:</span></a>
<a class="sourceLine" id="cb310-12" title="12"><span class="kw">mean</span>(sim_results)</a></code></pre></div>
<pre><code>[1] 0</code></pre>
<div class="sourceCode" id="section-cb312"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb312-1" title="1"><span class="co"># Okay... how many?</span></a>
<a class="sourceLine" id="cb312-2" title="2"><span class="kw">sum</span>(sim_results)</a></code></pre></div>
<pre><code>[1] 0</code></pre>
<p>In <span class="math inline">\(B = 10,000\)</span> simulations, I didn’t even get a single dataset that was as extreme
as ours. This provides strong evidence against the notion that the digits are, in
fact, evenly distributed.</p>
<p><strong>Exercise</strong>: how many simulations do you need before you get even one that is as
extreme as our dataset?</p>
</div>
<div id="section-testing-goodness-of-fit-math" class="section level3">
<h3><span class="header-section-number">10.2.4</span> Testing goodness of fit: math</h3>
<p>We may also use mathematics and statistical modelling to answer the question:
<strong>if the underlying distribution of last digits
really was evenly distributed, what is the probability of seeing the data that
we saw, or a dataset that is even more extreme under this hypothesis?</strong>.</p>
<p>We do this in a clever way: we construct a statistical model that represents the
truth, <em>if</em> the truth is what we say it is. Namely, we will define a probability
distribution that <em>should</em> represent the distribution of the last digits of our
measurements, <em>if</em> the last digits are evenly distributed. We then see how probable
our data is under this model. If, under this model, it is very unlikely to see
a dataset like ours, then this provides evidence that the model isn’t representative
of the truth. And since the model was built under the premise that the digits are
evenly distributed, a lack of fit of the model to the observed data provides
evidence against the notion that the digits are evenly distributed.</p>
<p>Let’s develop a model. Define <span class="math inline">\(y_{ij} = 1\)</span> if the last digit of the <span class="math inline">\(i^{th}\)</span> measurement
equals <span class="math inline">\(j\)</span>, for <span class="math inline">\(j \in J = \left\{1,2,3,4,6,7,8,9\right\}\)</span>, and equals <span class="math inline">\(0\)</span> otherwise. So for example,
if the <span class="math inline">\(i^{th}\)</span> measurement is <span class="math inline">\(42\)</span> then <span class="math inline">\(y_{i1} = 0\)</span> and <span class="math inline">\(y_{i2} = 1\)</span> and <span class="math inline">\(y_{i3} = 0\)</span>
and so on. Define <span class="math inline">\(y_{i} = (y_{i1},\ldots,y_{i9})\)</span>, a vector containing all zeroes
except for exactly one <span class="math inline">\(1\)</span>. Then the <span class="math inline">\(y_{i}\)</span> are independent draws from a <strong>Multinomial</strong>
distribution, <span class="math inline">\(y_{i}\overset{iid}{\sim}\text{Multinomial}(1,p_{1},\ldots,p_{9})\)</span>,
with <span class="math inline">\(\mathbb{E}(y_{ij}) = \mathbb{P}(y_{ij} = 1) = p_{j}\)</span> and <span class="math inline">\(\sum_{j\in J}p_{j} = 1\)</span>.
The vectors <span class="math inline">\(y_{i}\)</span> have the following (joint) density function:
<span class="math display">\[\begin{equation}
\mathbb{P}(y_{i} = (y_{i1},\ldots,y_{i9})) = p_{1}^{y_{i1}}\times\cdots\times p_{9}^{y_{i9}}
\end{equation}\]</span>
The multinomial is the generalization of the binomial/bernoulli to multiple possible
outcomes on each trial. If the bernoulli is thought of as flipping a coin (two possible
outcomes), then the multinomial should be thought of as rolling a die (six possible outcomes).</p>
<p>How does this help us answer the question? If the digits are actually evenly distributed,
then this means <span class="math inline">\(p_{1} = \cdots = p_{9} = 1/8\)</span> (why?).</p>
<p>However, the data might tell us something different. We estimate the <span class="math inline">\(p_{j}\)</span> from
out data <span class="math inline">\(y_{1},\ldots,y_{n}\)</span> by computing the maximum likelihood estimator:
<span class="math display">\[\begin{equation}
\hat{p}_{j} \ \frac{1}{n}\sum_{i=1}^{n}y_{ij}
\end{equation}\]</span>
which are simply the sample proportions of digits that equal each value of <span class="math inline">\(j\)</span>.</p>
<p>We assess how close the MLEs are to what the true values <em>ought</em> to be using the
<strong>likelihood ratio</strong>. For <span class="math inline">\(p_{0} = (1/8,\ldots,1/8)\)</span>, <span class="math inline">\(\hat{p} = (\hat{p}_{1},\ldots,\hat{p}_{9})\)</span>,
and <span class="math inline">\(L(\cdot)\)</span> the likelihood based off of the multinomial density,
<span class="math display">\[\begin{equation}
\Lambda = \frac{L(p_{0})}{L(\hat{p})}
\end{equation}\]</span>
Remember the definition of the likelihood, for discrete data: for any <span class="math inline">\(p\)</span>, <span class="math inline">\(L(p)\)</span> is the relative
frequency with which the observed data would be seen in repeated sampling, if the true
parameter value were <span class="math inline">\(p\)</span>. The likelihood ratio <span class="math inline">\(\Lambda\)</span> is the ratio of how often
our data would be seen if <span class="math inline">\(p = p_{0}\)</span>, against how often it would be seen if <span class="math inline">\(p = \hat{p}\)</span>.
If <span class="math inline">\(\Lambda = 0.5\)</span>, for example, that means that our data would occur half as often
if <span class="math inline">\(p = p_{0}\)</span>, compared to if <span class="math inline">\(p = \hat{p}\)</span>. Note that <span class="math inline">\(0 &lt; \Lambda \leq 1\)</span> (why?).</p>
<p>Lower values of <span class="math inline">\(\Lambda\)</span> mean that there is stronger evidence <em>against</em> the notion
that <span class="math inline">\(p_{0}\)</span> is a plausible value for <span class="math inline">\(p\)</span>– that is, that the digits are evenly
distributed. But how do we quantify how much less likely is less likely enough?
Here is where our previous question comes back. We ask: <strong>if the digits were
evenly distributed, what is the probability of seeing the data we saw, or something
with an even more extreme distribution of digits</strong>? To compute this, we need to
be able to compute probabilities involving <span class="math inline">\(\Lambda\)</span>.</p>
<p>It turns out that using <span class="math inline">\(\Lambda\)</span> is very clever, because well, we can do this.
There is a Big Theorem which states that if <span class="math inline">\(p\in\mathbb{R}^{d}\)</span> and <span class="math inline">\(p = p_{0}\)</span>,
<span class="math display">\[\begin{equation}
-2\log\Lambda \overset{\cdot}{\sim} \chi_{d-1}^{2}
\end{equation}\]</span>
So, if the digits are evenly distributed, then <em>our</em> value of <span class="math inline">\(-2\log\Lambda\)</span> should
be a realization of a <span class="math inline">\(\chi^{2}_{7}\)</span> random variable. We therefore compute
<span class="math display">\[\begin{equation}
\nu = \mathbb{P}\left(\chi^{2}_{7} \geq -2\log\Lambda\right)
\end{equation}\]</span>
The quantity <span class="math inline">\(\nu\)</span> is the probability of observing a distribution of digits
as or more extreme than the one we observed in our data, <em>if the distribution
of digits truly is even</em>. It’s called a <strong>p-value</strong>, and it’s one helpful
summary statistic in problems where the research question concerns comparing
observations to some sort of reference, like we’re doing here.</p>
<p>Let’s compute the likelihood ratio for our data:</p>
<div class="sourceCode" id="section-cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" title="1"><span class="co"># Compute the MLEs</span></a>
<a class="sourceLine" id="cb314-2" title="2">study1_filtered &lt;-<span class="st"> </span>study1_clean <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-3" title="3"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>(last_digit <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">0</span>))) <span class="co"># Should have done this before...</span></a>
<a class="sourceLine" id="cb314-4" title="4">pmledat &lt;-<span class="st"> </span>study1_filtered <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-5" title="5"><span class="st">  </span><span class="kw">group_by</span>(last_digit) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb314-6" title="6"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">cnt =</span> <span class="kw">n</span>(),</a>
<a class="sourceLine" id="cb314-7" title="7">            <span class="dt">pp =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(study1_filtered))</a>
<a class="sourceLine" id="cb314-8" title="8"></a>
<a class="sourceLine" id="cb314-9" title="9">obsvec &lt;-<span class="st"> </span>pmledat<span class="op">$</span>cnt</a>
<a class="sourceLine" id="cb314-10" title="10"><span class="kw">names</span>(obsvec) &lt;-<span class="st"> </span>pmledat<span class="op">$</span>last_digit</a>
<a class="sourceLine" id="cb314-11" title="11"></a>
<a class="sourceLine" id="cb314-12" title="12">pmle &lt;-<span class="st"> </span>pmledat<span class="op">$</span>pp</a>
<a class="sourceLine" id="cb314-13" title="13"><span class="kw">names</span>(pmle) &lt;-<span class="st"> </span>pmledat<span class="op">$</span>last_digit</a>
<a class="sourceLine" id="cb314-14" title="14">pmle</a></code></pre></div>
<pre><code>     2      3      4      6      7      8      9 
0.0074 0.5259 0.0148 0.0222 0.3556 0.0519 0.0222 </code></pre>
<div class="sourceCode" id="section-cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" title="1"><span class="co"># Truth, if digits evenly distributed</span></a>
<a class="sourceLine" id="cb316-2" title="2">p0 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>,<span class="kw">length</span>(pmle)) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(pmle)</a>
<a class="sourceLine" id="cb316-3" title="3"><span class="kw">names</span>(p0) &lt;-<span class="st"> </span><span class="kw">names</span>(pmle)</a>
<a class="sourceLine" id="cb316-4" title="4">p0</a></code></pre></div>
<pre><code>   2    3    4    6    7    8    9 
0.14 0.14 0.14 0.14 0.14 0.14 0.14 </code></pre>
<div class="sourceCode" id="section-cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" title="1"><span class="co"># Compute minus twice the likelihood ratio</span></a>
<a class="sourceLine" id="cb318-2" title="2">multinom_log_likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(x,p) {</a>
<a class="sourceLine" id="cb318-3" title="3">  <span class="co"># x: named vector where the name is j and the value is the count of </span></a>
<a class="sourceLine" id="cb318-4" title="4">  <span class="co"># times y_ij = 1 in the sample</span></a>
<a class="sourceLine" id="cb318-5" title="5">  <span class="co"># p: named vector with names equal to the unique values of x,</span></a>
<a class="sourceLine" id="cb318-6" title="6">  <span class="co"># containing probabilities of each</span></a>
<a class="sourceLine" id="cb318-7" title="7">  <span class="kw">sum</span>(x <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p[<span class="kw">names</span>(x)]))</a>
<a class="sourceLine" id="cb318-8" title="8">}</a>
<a class="sourceLine" id="cb318-9" title="9"></a>
<a class="sourceLine" id="cb318-10" title="10">lr &lt;-<span class="st"> </span><span class="dv">-2</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">multinom_log_likelihood</span>(obsvec,p0) <span class="op">-</span><span class="st"> </span><span class="kw">multinom_log_likelihood</span>(obsvec,pmle))</a>
<a class="sourceLine" id="cb318-11" title="11">lr</a></code></pre></div>
<pre><code>[1] 221</code></pre>
<div class="sourceCode" id="section-cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" title="1"><span class="co"># Compute the probability that a chisquare random variable is greater than this</span></a>
<a class="sourceLine" id="cb320-2" title="2"><span class="co"># value:</span></a>
<a class="sourceLine" id="cb320-3" title="3"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(lr,<span class="dt">df =</span> <span class="kw">length</span>(pmle) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># zero.</span></a></code></pre></div>
<pre><code>[1] 0</code></pre>
<p><strong>Exercise</strong>: write your own function to implement the multinomial loglikelihood,
using the <code>dmultinom</code> function and a <code>for</code> loop. Compare your results to mine.</p>
<p>We would interpret this result as: the observed data provides strong evidence against the notion
that the digits are evenly distributed.</p>
<p>The fact that there is essentially <em>zero chance</em> of seeing what we saw if our
claim that the digits are evenly distributed agrees with our simulation. We just
did some statistical forensics! Pretty cool. This type of reasoning is abundant
in the scientific literature, as are these p-value things. They are useful, but
we want you, as stats majors and specialists, to leave this course understanding
than statistics is so very much more than just a ritual or toolbox!</p>

<div class="sourceCode" id="section-cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" title="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-supplement-to-chapter-23-and-24.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-supplement-to-evans-rosenthal-section-7-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
